{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blobfile version 3.0.0\n",
      "huggingface_hub version 0.25.1\n",
      "tiktoken version 0.7.0\n",
      "torch version 2.4.1+cu118\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"blobfile\",\n",
    "    \"huggingface_hub\",\n",
    "    \"tiktoken\",\n",
    "    \"torch\"\n",
    "]\n",
    "\n",
    "for p in pkgs: \n",
    "    print(f\"{p} version {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class FeedForward(nn.Module): \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
    "        self.fc2 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
    "        self.fc3 = nn.Linear(cfg[\"hidden_dim\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_fc1 = self.fc1(x)\n",
    "        x_fc2 = self.fc2(x)\n",
    "        x = nn.functional.silu(x_fc1) * x_fc2\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_rope_params(head_dim, theta_base=10000, context_length=4096, freq_config=None):\n",
    "    assert head_dim % 2 == 0, \"Embedding dimension must be even\"\n",
    "\n",
    "    inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim // 2) / (head_dim // 2)))\n",
    "\n",
    "    if freq_config is not None:\n",
    "        low_freq_wavelen = freq_config[\"original_context_length\"] / freq_config[\"low_freq_factor\"]\n",
    "        high_freq_wavelen = freq_config[\"original_context_length\"] / freq_config[\"high_freq_factor\"]\n",
    "\n",
    "        wavelen = 2 * torch.pi / inv_freq \n",
    "\n",
    "        inv_freq_llama = torch.where(\n",
    "            wavelen > low_freq_wavelen, inv_freq / freq_config[\"factor\"], inv_freq\n",
    "        )\n",
    "\n",
    "        smooth_factor = (freq_config[\"original_context_length\"] / wavelen - freq_config[\"low_freq_factor\"]) / (\n",
    "            freq_config[\"high_freq_factor\"] - freq_config[\"low_freq_factor\"]\n",
    "        )\n",
    "\n",
    "        smoothed_inv_freq = (\n",
    "            (1 - smooth_factor) * (inv_freq / freq_config[\"factor\"]) + smooth_factor * inv_freq\n",
    "        )\n",
    "\n",
    "        is_medium_freq = (wavelen <= low_freq_wavelen) & (wavelen >= high_freq_wavelen)\n",
    "        inv_freq_llama = torch.where(is_medium_freq, smoothed_inv_freq, inv_freq_llama)\n",
    "        inv_freq = inv_freq_llama\n",
    "\n",
    "    positions = torch.arange(context_length)\n",
    "    angles = positions[:, None] * inv_freq[None, :]\n",
    "\n",
    "    cos = torch.cos(angles)\n",
    "    sin = torch.sin(angles)\n",
    "\n",
    "    return cos, sin\n",
    "\n",
    "def compute_rope(x, cos, sin):\n",
    "    # x: (batch_size, num_heads, seq_len, head_dim)\n",
    "    batch_size, num_heads, seq_len, head_dim = x.shape\n",
    "    assert head_dim % 2 == 0, \"Head dimension must be even\"\n",
    "\n",
    "    x1 = x[..., : head_dim // 2]\n",
    "    x2 = x[..., head_dim // 2 :]\n",
    "\n",
    "    cos = cos[:seq_len, :].unsqueeze(0).unsqueeze(0)\n",
    "    sin = sin[:seq_len, :].unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    rotated = torch.cat((-x2, x1), dim=-1)\n",
    "    x_rotated = (x * cos) + (rotated * sin)\n",
    "\n",
    "    return x_rotated.to(dtype=x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupedQueryAttention(nn.Module):\n",
    "    def __init__(\n",
    "            self, d_in, d_out, context_length, num_heads,\n",
    "            num_kv_groups, \n",
    "            rope_base=10000,\n",
    "            rope_config=None,\n",
    "            dtype=None\n",
    "        ):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        assert num_heads % num_kv_groups == 0, \"num_heads must be divisible by num_kv_groups\"\n",
    "\n",
    "        self.d_out = d_out \n",
    "        self.num_heads = num_heads \n",
    "        self.head_dim = d_out // num_heads \n",
    "\n",
    "        self.W_key = nn.Linear(d_in, num_kv_groups * self.head_dim, bias=False, dtype=dtype)\n",
    "        self.W_value = nn.Linear(d_in, num_kv_groups * self.head_dim, bias=False, dtype=dtype)\n",
    "        self.num_kv_groups = num_kv_groups  \n",
    "        self.group_size = num_heads // num_kv_groups\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=False, dtype=dtype)\n",
    "        self.out_proj = nn.Linear(d_out, d_out, bias=False, dtype=dtype)\n",
    "\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "        cos, sin = precompute_rope_params(\n",
    "            head_dim=self.head_dim, \n",
    "            theta_base=rope_base,\n",
    "            freq_config=rope_config,\n",
    "            context_length=8192\n",
    "        )\n",
    "        self.register_buffer(\"cos\", cos)\n",
    "        self.register_buffer(\"sin\", sin)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_token, d_in = x.shape\n",
    "\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        queries = queries.view(b, num_token, self.num_heads, self.head_dim)\n",
    "        keys = keys.view(b, num_token, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_token, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "\n",
    "        keys = compute_rope(keys, self.cos, self.sin)\n",
    "        queries = compute_rope(queries, self.cos, self.cin)\n",
    "\n",
    "        keys = keys.repeat_interleave(self.group_size, dim=1)\n",
    "        values = values.repeat_interleave(self.group_size, dim=1)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3) # dot prod for each head\n",
    "        mask_bool = self.mask.bool()[:num_token, :num_token]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        assert keys.shape[-1] == self.head_dim\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        context_vec = context_vec.reshape(b, num_token, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att =  GroupedQueryAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            num_kv_groups=cfg[\"n_kv_groups\"],\n",
    "            rope_base=cfg[\"rope_base\"],\n",
    "            rope_config=cfg[\"rope_freq\"],\n",
    "            dtype=cfg[\"dtype\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = nn.RMSNorm(cfg[\"emb_dim\"], eps=1e-5)\n",
    "        self.norm2 = nn.RMSNorm(cfg[\"emb_dim\"], eps=1e-5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x \n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x.to(torch.bfloat16))\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llama3Model(nn.Module):\n",
    "    def __init__(self, cfg): \n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = nn.RMSNorm(cfg[\"emb_dim\"], eps=1e-5)\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False, dtype=cfg[\"dtype\"])\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        x = tok_embeds\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x.to(torch.bfloat16))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA32_CONFIG = {\n",
    "    \"vocab_size\": 128_256,\n",
    "    \"context_length\": 8192, \n",
    "    \"emb_dim\": 2048, \n",
    "    \"n_heads\": 32, \n",
    "    \"n_layers\": 16, \n",
    "    \"hidden_dim\": 8192,\n",
    "    \"n_kv_groups\": 8, \n",
    "    \"rope_base\": 50_000,\n",
    "    \"dtype\": torch.bfloat16, \n",
    "    \"rope_freq\": {\n",
    "        \"factor\": 32.0, \n",
    "        \"low_freq_factor\": 1.0,\n",
    "        \"high_freq_factor\": 4.0,\n",
    "        \"original_context_length\": 8182\n",
    "    }\n",
    "}\n",
    "\n",
    "LLAMA_SIZE_STR = \"1B\" if LLAMA32_CONFIG[\"emb_dim\"] == 2048 else \"3B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Llama3Model(LLAMA32_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 1,498,482,688\n",
      "\n",
      "Total number of unique parameters: 1,235,814,400\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")\n",
    "\n",
    "# Account for weight tying\n",
    "total_params_normalized = total_params - model.tok_emb.weight.numel()\n",
    "print(f\"\\nTotal number of unique parameters: {total_params_normalized:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 (PyTorch default): 15.20 GB\n",
      "bfloat16: 7.60 GB\n"
     ]
    }
   ],
   "source": [
    "def model_memory_size(model, input_dtype=torch.float32):\n",
    "    total_params = 0\n",
    "    total_grads = 0\n",
    "    for param in model.parameters():\n",
    "        param_size = param.numel()\n",
    "        total_params += param_size\n",
    "        if param.requires_grad:\n",
    "            total_grads += param_size\n",
    "\n",
    "    total_buffers = sum(buf.numel() for buf in model.buffers())\n",
    "    element_size = torch.tensor(0, dtype=input_dtype).element_size()\n",
    "    total_memory_bytes = (total_params + total_grads + total_buffers) * element_size\n",
    "\n",
    "    total_memory_gb = total_memory_bytes / (1024**3)\n",
    "    \n",
    "    return total_memory_gb\n",
    "\n",
    "print(f\"float32 (PyTorch default): {model_memory_size(model, input_dtype=torch.float32):.2f} GB\")\n",
    "print(f\"bfloat16: {model_memory_size(model, input_dtype=torch.bfloat16):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Llama3Model(\n",
       "  (tok_emb): Embedding(128256, 2048)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  (out_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path \n",
    "\n",
    "import tiktoken \n",
    "from tiktoken.load import load_tiktoken_bpe\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, model_path):\n",
    "        assert os.path.isfile(model_path), f\"Model file {model_path} not found\"\n",
    "        mergeable_ranks = load_tiktoken_bpe(model_path)\n",
    "        num_base_tokens = len(mergeable_ranks)\n",
    "\n",
    "        self.special_tokens = {\n",
    "            \"<|begin_of_text|>\": 128000,\n",
    "            \"<|end_of_text|>\": 128001,\n",
    "            \"<|start_header_id|>\": 128006,\n",
    "            \"<|end_header_id|>\": 128007,\n",
    "            \"<|eot_id|>\": 128009,\n",
    "        }\n",
    "\n",
    "        self.special_tokens.update({\n",
    "            f\"<|reserved_{i}|>\": 128002 + i for i in range(256) if (128002 + i) not in self.special_tokens.values()\n",
    "        })\n",
    "\n",
    "        self.model = tiktoken.Encoding(\n",
    "            name=Path(model_path).name,\n",
    "            pat_str=r\"(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+\",\n",
    "            mergeable_ranks=mergeable_ranks,\n",
    "            special_tokens=self.special_tokens\n",
    "        )\n",
    "\n",
    "    def encode(self, text, bos=False, eos=False, allowed_special=set(), disallowed_special=()):\n",
    "        if bos: \n",
    "            tokens = [self.special_tokens[\"<|begin_of_text|>\"]]\n",
    "        else:\n",
    "            tokens = []\n",
    "        \n",
    "        tokens += self.model.encode(text, allowed_special=allowed_special, disallowed_special=disallowed_special)\n",
    "\n",
    "        if eos:\n",
    "            tokens.append(self.special_tokens[\"<|end_of_text|>\"])\n",
    "        return tokens \n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        return self.model.decode(tokens)\n",
    "    \n",
    "\n",
    "class ChatFormat: \n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def encode_header(self, message):\n",
    "        tokens = []\n",
    "        tokens.append(self.tokenizer.special_tokens[\"<|start_header_id|>\"])\n",
    "        tokens.extend(self.tokenizer.encode(message[\"role\"], bos=False, eos=False))\n",
    "        tokens.append(self.tokenizer.special_tokens[\"<|end_header_id|>\"])\n",
    "        tokens.extend(self.tokenizer.encode(\"\\n\\n\", bos=False, eos=False))\n",
    "        return tokens\n",
    "    \n",
    "    def encode(self, text):\n",
    "        message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": text\n",
    "        }\n",
    "\n",
    "        tokens = self.encode_header(message)\n",
    "        tokens.extend(\n",
    "            self.tokenizer.encode(message[\"content\"].strip(), bos=False, eos=False)\n",
    "        )\n",
    "        tokens.append(self.tokenizer.special_tokens[\"<|eot_id|>\"])\n",
    "        return tokens \n",
    "    \n",
    "    def decode(self, token_ids):\n",
    "        return self.tokenizer.decode(token_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93684f8e7fe54e079f2cf4bb6830bca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 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\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "tokenizer_file_path = hf_hub_download(\n",
    "    repo_id=f\"meta-llama/Llama-3.2-{LLAMA_SIZE_STR}-Instruct\",\n",
    "    filename=\"original/tokenizer.model\",\n",
    "    local_dir=\"llama32-files\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tokenizer_file_path)\n",
    "chat_tokenizer = ChatFormat(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right, tensor_name=\"unknown\"):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch in tensor '{tensor_name}'. Left: {left.shape}, Right: {right.shape}\")\n",
    "\n",
    "    if isinstance(right, torch.Tensor):\n",
    "        return torch.nn.Parameter(right.clone().detach())\n",
    "    else: \n",
    "        return torch.nn.Parameter(torch.tensor(right))\n",
    "    \n",
    "\n",
    "def load_weights_into_llama(model, param_config, params):\n",
    "    model.tok_emb.weight = assign(model.tok_emb.weight, params[\"model.embed_tokens.weight\"], \"model.embed_tokens.weight\")\n",
    "\n",
    "    for l in range(param_config[\"n_layers\"]):\n",
    "\n",
    "        # Load attention weights\n",
    "        model.trf_blocks[l].att.W_query.weight = assign(\n",
    "            model.trf_blocks[l].att.W_query.weight,\n",
    "            params[f\"model.layers.{l}.self_attn.q_proj.weight\"],\n",
    "            f\"model.layers.{l}.self_attn.q_proj.weight\"\n",
    "        )\n",
    "        model.trf_blocks[l].att.W_key.weight = assign(\n",
    "            model.trf_blocks[l].att.W_key.weight,\n",
    "            params[f\"model.layers.{l}.self_attn.k_proj.weight\"],\n",
    "            f\"model.layers.{l}.self_attn.k_proj.weight\"\n",
    "        )\n",
    "        model.trf_blocks[l].att.W_value.weight = assign(\n",
    "            model.trf_blocks[l].att.W_value.weight,\n",
    "            params[f\"model.layers.{l}.self_attn.v_proj.weight\"],\n",
    "            f\"model.layers.{l}.self_attn.v_proj.weight\"\n",
    "        )\n",
    "        model.trf_blocks[l].att.out_proj.weight = assign(\n",
    "            model.trf_blocks[l].att.out_proj.weight,\n",
    "            params[f\"model.layers.{l}.self_attn.o_proj.weight\"],\n",
    "            f\"model.layers.{l}.self_attn.o_proj.weight\"\n",
    "        )\n",
    "        model.trf_blocks[l].norm1.weight = assign(\n",
    "            model.trf_blocks[l].norm1.weight,\n",
    "            params[f\"model.layers.{l}.input_layernorm.weight\"],\n",
    "            f\"model.layers.{l}.input_layernorm.weight\"\n",
    "        )\n",
    "\n",
    "        # Load FeedForward weights\n",
    "        model.trf_blocks[l].ff.fc1.weight = assign(\n",
    "            model.trf_blocks[l].ff.fc1.weight,\n",
    "            params[f\"model.layers.{l}.mlp.gate_proj.weight\"],\n",
    "            f\"model.layers.{l}.mlp.gate_proj.weight\"\n",
    "        )\n",
    "        model.trf_blocks[l].ff.fc2.weight = assign(\n",
    "            model.trf_blocks[l].ff.fc2.weight,\n",
    "            params[f\"model.layers.{l}.mlp.up_proj.weight\"],\n",
    "            f\"model.layers.{l}.mlp.up_proj.weight\"\n",
    "        )\n",
    "        model.trf_blocks[l].ff.fc3.weight = assign(\n",
    "            model.trf_blocks[l].ff.fc3.weight,\n",
    "            params[f\"model.layers.{l}.mlp.down_proj.weight\"],\n",
    "            f\"model.layers.{l}.mlp.down_proj.weight\"\n",
    "        )\n",
    "        model.trf_blocks[l].norm2.weight = assign(\n",
    "            model.trf_blocks[l].norm2.weight,\n",
    "            params[f\"model.layers.{l}.post_attention_layernorm.weight\"],\n",
    "            f\"model.layers.{l}.post_attention_layernorm.weight\"\n",
    "        )\n",
    "\n",
    "    # Load output layer weights\n",
    "    model.final_norm.weight = assign(model.final_norm.weight, params[\"model.norm.weight\"], \"model.norm.weight\")\n",
    "\n",
    "    if \"lm_head.weight\" in params.keys():\n",
    "        model.out_head.weight = assign(model.out_head.weight, params[\"lm_head.weight\"], \"lm_head.weight\")\n",
    "    else:\n",
    "        model.out_head.weight = assign(model.out_head.weight, params[\"model.embed_tokens.weight\"], \"model.embed_tokens.weight\")\n",
    "        print(\"Model uses weight tying.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uses weight tying.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Llama3Model(\n",
       "  (tok_emb): Embedding(128256, 2048)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n",
       "        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): RMSNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  (out_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from safetensors.torch import load_file \n",
    "\n",
    "if LLAMA_SIZE_STR == \"1B\":\n",
    "    weights_file = hf_hub_download(\n",
    "        repo_id=f\"meta-llama/Llama-3.2-{LLAMA_SIZE_STR}-Instruct\",\n",
    "        filename=f\"model.safetensors\",\n",
    "        local_dir=\"llama32-files\"\n",
    "    )\n",
    "    combined_weights = load_file(weights_file)\n",
    "\n",
    "else:\n",
    "    combined_weights = {}\n",
    "    for i in range(1, 3):\n",
    "        weights_file = hf_hub_download(\n",
    "            repo_id=f\"meta-llama/Llama-3.2-{LLAMA_SIZE_STR}-Instruct\",\n",
    "            filename=f\"model-0000{i}-of-00002.safetensors\",\n",
    "            local_dir=\"llama3-files\"\n",
    "        )\n",
    "        current_weights = load_file(weights_file)\n",
    "        combined_weights.update(current_weights)\n",
    "    \n",
    "\n",
    "load_weights_into_llama(model, LLAMA32_CONFIG, combined_weights)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight tying: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Weight tying:\", torch.equal(model.tok_emb.weight, model.out_head.weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "    idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output_text:\n",
      " <|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what to llamas eat?<|eot_id|><|start_header_id|>\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "PROMPT = \"what to llamas eat?\"\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(PROMPT, chat_tokenizer).to(device),\n",
    "    max_new_tokens=150,\n",
    "    context_size=LLAMA32_CONFIG[\"context_length\"],\n",
    "    top_k=1,\n",
    "    temperature=0, \n",
    "    eos_id=\"<|end_of_text|>\"\n",
    ")\n",
    "\n",
    "output_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "def clean_text(text, header_end=\"assistant<|end_header_id|>\\n\\n\"):\n",
    "    index = text.find(header_end)\n",
    "\n",
    "    if index != -1:\n",
    "        return text[index + len(header_end):].strip()\n",
    "    else:\n",
    "        return text \n",
    "    \n",
    "print(\"Output_text:\\n\", clean_text(output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
